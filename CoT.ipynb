{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTEL/+IGS+SlVcfOYSM6FQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodinkod/CoT_Research/blob/main/CoT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install petals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azjC9ORfJafM",
        "outputId": "e8f36d57-c4cd-41de-cbf0-dd422f9bac35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting petals\n",
            "  Downloading petals-1.1.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.12 in /usr/local/lib/python3.8/dist-packages (from petals) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from petals) (23.0)\n",
            "Collecting transformers==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hivemind==1.1.5\n",
            "  Downloading hivemind-1.1.5-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensor-parallel==1.0.23\n",
            "  Downloading tensor_parallel-1.0.23-py3-none-any.whl (25 kB)\n",
            "Collecting humanfriendly\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from petals) (4.0.2)\n",
            "Collecting accelerate==0.15.0\n",
            "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 KB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.34.0\n",
            "  Downloading bitsandbytes-0.34.0-py3-none-any.whl (55.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting speedtest-cli==2.1.3\n",
            "  Downloading speedtest_cli-2.1.3-py2.py3-none-any.whl (23 kB)\n",
            "Collecting cpufeature>=0.2.0\n",
            "  Downloading cpufeature-0.2.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting huggingface-hub==0.11.1\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.15.0->petals) (1.21.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate==0.15.0->petals) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate==0.15.0->petals) (6.0)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.8/dist-packages (from hivemind==1.1.5->petals) (1.0.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from hivemind==1.1.5->petals) (2.4.0)\n",
            "Collecting multiaddr>=0.0.9\n",
            "  Downloading multiaddr-0.0.9-py2.py3-none-any.whl (16 kB)\n",
            "Collecting uvloop>=0.14.0\n",
            "  Downloading uvloop-0.17.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography>=3.4.6\n",
            "  Downloading cryptography-39.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from hivemind==1.1.5->petals) (1.10.4)\n",
            "Requirement already satisfied: prefetch-generator>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from hivemind==1.1.5->petals) (1.0.3)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from hivemind==1.1.5->petals) (1.7.3)\n",
            "Collecting pymultihash>=0.8.2\n",
            "  Downloading pymultihash-0.8.2-py3-none-any.whl (13 kB)\n",
            "Collecting grpcio-tools>=1.33.2\n",
            "  Downloading grpcio_tools-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0.0,>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from hivemind==1.1.5->petals) (3.19.6)\n",
            "Collecting configargparse>=1.2.3\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub==0.11.1->petals) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub==0.11.1->petals) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub==0.11.1->petals) (4.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub==0.11.1->petals) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1->petals) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.4.6->hivemind==1.1.5->petals) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.51.1 in /usr/local/lib/python3.8/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.5->petals) (1.51.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.5->petals) (57.4.0)\n",
            "Collecting grpcio-tools>=1.33.2\n",
            "  Downloading grpcio_tools-1.50.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.49.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.48.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting varint\n",
            "  Downloading varint-1.0.2.tar.gz (1.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from multiaddr>=0.0.9->hivemind==1.1.5->petals) (1.15.0)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting netaddr\n",
            "  Downloading netaddr-0.8.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub==0.11.1->petals) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub==0.11.1->petals) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub==0.11.1->petals) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub==0.11.1->petals) (4.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind==1.1.5->petals) (2.21)\n",
            "Building wheels for collected packages: varint\n",
            "  Building wheel for varint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for varint: filename=varint-1.0.2-py3-none-any.whl size=1978 sha256=f1f548c29283223bbb98ecd995fa0c6704d4b2d797db4d8d51bc14e27a065120\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/a8/a4/4d9e9807c27585dc974fc0e86a3e4345649d71f8a35906d1a8\n",
            "Successfully built varint\n",
            "Installing collected packages: varint, tokenizers, speedtest-cli, pymultihash, netaddr, cpufeature, bitsandbytes, uvloop, humanfriendly, grpcio-tools, configargparse, base58, multiaddr, huggingface-hub, cryptography, accelerate, transformers, hivemind, tensor-parallel, petals\n",
            "Successfully installed accelerate-0.15.0 base58-2.1.1 bitsandbytes-0.34.0 configargparse-1.5.3 cpufeature-0.2.1 cryptography-39.0.1 grpcio-tools-1.48.2 hivemind-1.1.5 huggingface-hub-0.11.1 humanfriendly-10.0 multiaddr-0.0.9 netaddr-0.8.0 petals-1.1.2 pymultihash-0.8.2 speedtest-cli-2.1.3 tensor-parallel-1.0.23 tokenizers-0.13.2 transformers-4.25.1 uvloop-0.17.0 varint-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BloomTokenizerFast\n",
        "from petals import DistributedBloomForCausalLM\n",
        "\n",
        "MODEL_NAME = \"bigscience/bloom-petals\"\n",
        "tokenizer = BloomTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "model = DistributedBloomForCausalLM.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BSvEeKALjuj",
        "outputId": "4bef87c1-0935-4023-ade2-28317d9a11a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Feb 19 14:13:34.223 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1m/usr/local/lib/python3.8/dist-packages/petals/client/routing/sequence_manager.py._update:197\u001b[0m] Could not find route through the model: MissingBlocksError(\"No servers holding blocks [28, 29, 30] are online.\\nYou can check the public swarm's state at http://health.petals.ml\\n\\nIf there are not enough servers, please consider connecting your own GPU:\\nhttps://github.com/bigscience-workshop/petals#connect-your-gpu-and-increase-petals-capacity\") (retry in 0 sec)\n",
            "Feb 19 14:13:37.894 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1m/usr/local/lib/python3.8/dist-packages/petals/client/routing/sequence_manager.py._update:197\u001b[0m] Could not find route through the model: MissingBlocksError(\"No servers holding blocks [28, 29, 30] are online.\\nYou can check the public swarm's state at http://health.petals.ml\\n\\nIf there are not enough servers, please consider connecting your own GPU:\\nhttps://github.com/bigscience-workshop/petals#connect-your-gpu-and-increase-petals-capacity\") (retry in 1 sec)\n",
            "Feb 19 14:13:42.644 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1m/usr/local/lib/python3.8/dist-packages/petals/client/routing/sequence_manager.py._update:197\u001b[0m] Could not find route through the model: MissingBlocksError(\"No servers holding blocks [28, 29, 30] are online.\\nYou can check the public swarm's state at http://health.petals.ml\\n\\nIf there are not enough servers, please consider connecting your own GPU:\\nhttps://github.com/bigscience-workshop/petals#connect-your-gpu-and-increase-petals-capacity\") (retry in 2 sec)\n",
            "Feb 19 14:13:43.725 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1m/usr/local/lib/python3.8/dist-packages/petals/client/routing/sequence_manager.py._update:197\u001b[0m] Could not find route through the model: MissingBlocksError(\"No servers holding blocks [28, 29, 30] are online.\\nYou can check the public swarm's state at http://health.petals.ml\\n\\nIf there are not enough servers, please consider connecting your own GPU:\\nhttps://github.com/bigscience-workshop/petals#connect-your-gpu-and-increase-petals-capacity\") (retry in 512 sec)\n",
            "Feb 19 14:13:45.539 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1m/usr/local/lib/python3.8/dist-packages/petals/client/routing/sequence_manager.py._update:197\u001b[0m] Could not find route through the model: MissingBlocksError(\"No servers holding blocks [28, 29, 30] are online.\\nYou can check the public swarm's state at http://health.petals.ml\\n\\nIf there are not enough servers, please consider connecting your own GPU:\\nhttps://github.com/bigscience-workshop/petals#connect-your-gpu-and-increase-petals-capacity\") (retry in 4 sec)\n",
            "Feb 19 14:13:53.546 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1m/usr/local/lib/python3.8/dist-packages/petals/client/routing/sequence_manager.py._update:197\u001b[0m] Could not find route through the model: MissingBlocksError(\"No servers holding blocks [28, 29, 30] are online.\\nYou can check the public swarm's state at http://health.petals.ml\\n\\nIf there are not enough servers, please consider connecting your own GPU:\\nhttps://github.com/bigscience-workshop/petals#connect-your-gpu-and-increase-petals-capacity\") (retry in 8 sec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"A cat sat\", return_tensors=\"pt\")[\"input_ids\"]\n",
        "outputs = model.generate(inputs, max_new_tokens=5)\n",
        "print(tokenizer.decode(outputs[0]))  # A cat sat on a mat...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "k39M14U9LlJo",
        "outputId": "17afe371-6f0c-44a8-b97b-43724486d56d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e10dfc6cd835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A cat sat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# A cat sat on a mat...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"\n",
        "\n",
        "Question: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
        " \n",
        "Answer: The cost of the house and repairs came out to 80,000+50,000=$130,000\n",
        "He increased the value of the house by 80,000*1.5=120,000\n",
        "So the new value of the house is 120,000+80,000=$200,000\n",
        "So he made a profit of 200,000-130,000=$70,000\n",
        "The answer is  70000\n",
        "\n",
        "\n",
        "Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
        "\n",
        "Answer: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
        "\n",
        "\n",
        "Question: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
        "\n",
        "Answer: If each chicken eats 3 cups of feed per day, then for 20 chickens they would need 3*20=60 cups of feed per day.\n",
        "If she feeds the flock 15 cups of feed in the morning, and 25 cups in the afternoon, then the final meal would require 60-15-25=20 cups of chicken feed.\n",
        "The answer is 20.\n",
        " \n",
        "\n",
        "Question: Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\n",
        " \n",
        "Answer: The discount price of one glass is 60/100 * 5 = $3.\n",
        "If every second glass is cheaper, that means Kylar is going to buy 16 / 2 = 8 cheaper glasses.\n",
        "So for the cheaper glasses, Kylar is going to pay 8 * 3 = $24.\n",
        "And for the regular-priced glasses, Kylar will pay 8 * 5 = $40.\n",
        "So in total Kylar needs to pay 24 + 40 = $64 for the glasses he wants to buy.\n",
        "The answer is 64.\n",
        " \n",
        "\n",
        "Question: Toulouse has twice as many sheep as Charleston. Charleston has 4 times as many sheep as Seattle. How many sheep do Toulouse, Charleston, and Seattle have together if Seattle has 20 sheep?\n",
        " \n",
        "Answer: If Seattle has 20 sheep, Charleston has 4 * 20 sheep = 80 sheep\n",
        "Toulouse has twice as many sheep as Charleston, which is 2 * 80 sheep = 160 sheep\n",
        "Together, the three has 20 sheep + 160 sheep + 80 sheep = 260 sheep\n",
        "The answer is 260. \n",
        "\n",
        "\n",
        "Question: Kylar went to the store to buy glasses for his new apartment. One glass costs $8, but every second glass costs only 50% of the price. Kylar wants to buy 15 glasses. How much does he need to pay for them?\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer.encode(prefix, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs)\n",
        "print(tokenizer.decode(outputs[0]))\n"
      ],
      "metadata": {
        "id": "ETDH6kDKAZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXvDF0aFCBYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}